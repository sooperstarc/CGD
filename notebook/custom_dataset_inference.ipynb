{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yoo/works/CGD\n"
     ]
    }
   ],
   "source": [
    "%cd /home/yoo/works/CGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/custom 폴더 하위에 있는 이미지 파일(jpg, JPG)를 하나의 텍스트 파일에 정리\n",
    "# 파일 이름이 같은 경우에는 같은 라벨이 부여되도록 수정이 필요함(!!!)\n",
    "\n",
    "import os\n",
    "\n",
    "search_path = 'data/custom'\n",
    "target_ext = '.jpg'\n",
    "\n",
    "txt = open(\"{}/test.txt\".format(search_path), 'w')\n",
    "txt.write(\"image_id\\tclass_id\\tsuper_class_id\\tpath\")\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for (path, dir, files) in os.walk(search_path):\n",
    "\n",
    "    for filename in files:\n",
    "        ext = os.path.splitext(filename)[-1]\n",
    "\n",
    "        if path.split('/')[-1] != 'uncropped':\n",
    "            \n",
    "            if ext in ['.jpg', '.JPG']:\n",
    "                idx += 1\n",
    "                txt.write(\"\\n\")\n",
    "                txt.write(f\"_\\t{idx}\\t_\\t{os.path.join(path, filename)}\")\n",
    "                # txt.write(f\"_\\t{idx}\\t_\\t{filename}\")\n",
    "\n",
    "txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터베이스 생성 (uncropped_data_dicts.pth)\n",
    "\n",
    "import data_utils\n",
    "\n",
    "data_path = 'data/custom'\n",
    "\n",
    "data_utils.process_custom_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터베이스 확인\n",
    "\n",
    "import torch\n",
    "\n",
    "pth_path = 'data/custom/uncropped_data_dicts.pth'\n",
    "\n",
    "data_base = torch.load(pth_path)\n",
    "data_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing test data: 100%|██████████| 2/2 [00:01<00:00,  1.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from thop import profile, clever_format\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model import Model, set_bn_eval\n",
    "from utils import recall, LabelSmoothingCrossEntropyLoss, BatchHardTripletLoss, ImageReader, MPerClassSampler\n",
    "\n",
    "data_path = 'data'\n",
    "data_name = 'custom'\n",
    "crop_type = 'uncropped'\n",
    "backbone_type = 'resnet50'\n",
    "gd_config = 'SG'\n",
    "feature_dim = 1536\n",
    "smoothing = 0.1\n",
    "temperature = 0.5\n",
    "margin = 0.1\n",
    "recalls = '1,2,4,8'\n",
    "batch_size = 128\n",
    "\n",
    "save_name_pre = '{}_{}_{}_{}_{}_{}_{}_{}_{}'.format(data_name, crop_type, backbone_type, gd_config, feature_dim,\n",
    "                                                        smoothing, temperature, margin, batch_size)\n",
    "\n",
    "test_data_set = ImageReader(data_path, data_name, 'test', crop_type)\n",
    "test_data_loader = DataLoader(test_data_set, batch_size, shuffle=False, num_workers=8)\n",
    "eval_dict = {'test': {'data_loader': test_data_loader}}\n",
    "\n",
    "# model = Model(backbone_type, gd_config, feature_dim, num_classes=len(test_data_set.class_to_idx)).cuda()\n",
    "model = Model(backbone_type, gd_config, feature_dim, num_classes=11318).cuda()\n",
    "\n",
    "pretrained_model_path = 'results/sop_uncropped_resnet50_SG_1536_0.1_0.5_0.1_128_model.pth'\n",
    "model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # obtain feature vectors for all data\n",
    "    for key in eval_dict.keys():\n",
    "        eval_dict[key]['features'] = []\n",
    "        for inputs, labels in tqdm(eval_dict[key]['data_loader'], desc='processing {} data'.format(key)):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            features, classes = model(inputs)\n",
    "            eval_dict[key]['features'].append(features)\n",
    "        eval_dict[key]['features'] = torch.cat(eval_dict[key]['features'], dim=0)\n",
    "\n",
    "data_base = {}\n",
    "data_base['test_images'] = test_data_set.images\n",
    "data_base['test_labels'] = test_data_set.labels\n",
    "data_base['test_features'] = eval_dict['test']['features']\n",
    "# torch.save(model.state_dict(), 'results/{}_model.pth'.format(save_name_pre))\n",
    "torch.save(data_base, 'results/{}_data_base.pth'.format(save_name_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number \t image_path \t\t\t\t distance\n",
      "1 \t data/custom/uncropped/25732645526.jpg \t 0.4202\n",
      "2 \t data/custom/uncropped/24903715522.jpg \t 0.4648\n",
      "3 \t data/custom/uncropped/32035855621.jpg \t 0.4799\n",
      "4 \t data/custom/uncropped/25255997523.jpg \t 0.4868\n",
      "5 \t data/custom/uncropped/34271791619.jpg \t 0.5056\n",
      "6 \t data/custom/uncropped/32035866621.jpg \t 0.6053\n",
      "7 \t data/custom/uncropped/22847254426.jpg \t 0.7456\n",
      "8 \t data/custom/uncropped/21194929302.jpg \t 0.7632\n",
      "9 \t data/custom/uncropped/21412657451.jpg \t 0.8244\n",
      "10 \t data/custom/uncropped/36950336622.jpg \t 0.8389\n"
     ]
    }
   ],
   "source": [
    "!python test.py \\\n",
    "--query_img_name 'data/custom/uncropped/24903648525.jpg' \\\n",
    "--data_base 'results/custom_uncropped_resnet50_SG_1536_0.1_0.5_0.1_128_data_base.pth' \\\n",
    "--retrieval_num 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Jan 26 2023, 00:38:06) \n[GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7477bf70cb5c199d9228b8f8826ede3070e8bc378a87008e1002dbc64f6a554"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
